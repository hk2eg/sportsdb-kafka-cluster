---
services:
#####################################################
#### Kafka Cluster ##################################
#####################################################
  broker:
    image: confluentinc/cp-kafka:7.6.1
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
      - "9094:9094"        # ← exposes the SASL/PLAIN listener
      - "9095:9095"          # ← SASL_SSL  (for ClickPipe)
      - "9101:9101"
      - "1234:1234"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >-
        INTERNAL:PLAINTEXT,
        EXTERNAL:SASL_PLAINTEXT,
        EXTERNALSASL:SASL_PLAINTEXT,
        EXTERNALTLS:SASL_SSL,
        CONTROLLER:PLAINTEXT
      KAFKA_LISTENERS: >-
        INTERNAL://broker:29092,
        EXTERNAL://0.0.0.0:9092,
        EXTERNALSASL://0.0.0.0:9094,
        EXTERNALTLS://0.0.0.0:9095,
        CONTROLLER://broker:29093
      KAFKA_ADVERTISED_LISTENERS: >-
        INTERNAL://broker:29092,
        EXTERNAL://${EXT_PLAIN_HOST}:${EXT_PLAIN_PORT},
        EXTERNALSASL://${EXT_SASL_HOST}:${EXT_SASL_PORT},
        EXTERNALTLS://${TLS_HOST}:${TLS_PORT}
      KAFKA_INTER_BROKER_LISTENER_NAME: 'INTERNAL'
      
      KAFKA_SSL_KEYSTORE_TYPE:    JKS
      KAFKA_SSL_TRUSTSTORE_TYPE:  JKS
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/kafka.keystore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: m3troctyKafka2025
      KAFKA_SSL_KEY_PASSWORD:      m3troctyKafka2025
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: m3troctyKafka2025

      ## 🔑 enable SASL/PLAIN on the new listener
      KAFKA_SASL_ENABLED_MECHANISMS: 'PLAIN'
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: 'PLAIN'
      KAFKA_OPTS: >-
        -Djava.security.auth.login.config=/etc/kafka/jaas.conf
        -javaagent:/tmp/jmx/jmx_prometheus_javaagent.jar=1234:/tmp/jmx/broker.yml
      #KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      #KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      #KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      #KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      #https://docs.confluent.io/platform/current/monitor/cp-logging.html
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid" 
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      #https://medium.com/@oredata-engineering/setting-up-prometheus-grafana-for-kafka-on-docker-8a692a45966c
      #KAFKA_OPTS: -javaagent:/tmp/jmx/jmx_prometheus_javaagent.jar=1234:/tmp/jmx/broker.yml
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: "2.5g"
        reservations:
          cpus: '1'
          memory: "2.5g"
    volumes:
      - $PWD/secrets:/etc/kafka/secrets:ro
      - $PWD/jmx-exporter:/tmp/jmx/
      - $PWD/kafka_server_jaas.conf:/etc/kafka/jaas.conf:ro

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.1
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_JMX_OPTS: -javaagent:/tmp/jmx/jmx_prometheus_javaagent.jar=1234:/tmp/jmx/schema-registry.yml
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: "0.5g"
        reservations:
          cpus: '1'
          memory: "0.5g"
    volumes:
      - $PWD/jmx-exporter:/tmp/jmx/

  connect:
    image: confluentinc/cp-kafka-connect:7.7.1
    hostname: connect
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8083:8083"
      # - "9999:9999"
      - "1235:1234"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_CLEANUP_POLICY: compact
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.6.1.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/tmp/ext-plugins"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      CONNECT_PRODUCER_MAX_REQUEST_SIZE: 2097152
      # CONNECT_LOG4J_LOGGERS: "log4j.logger.io.confluent.<connector-name>=DEBUG,org.apache.kafka.connect=DEBUG"
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_JMX_OPTS: -javaagent:/tmp/jmx/jmx_prometheus_javaagent.jar=1234:/tmp/jmx/connect.yml -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false
       
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: "2g"
        reservations:
          cpus: '1'
          memory: "2g"
    volumes:
      # - ./connect-file.properties:/tmp/connect-file.properties
      # - $PWD/connectors:/tmp/data
      - $PWD/plugins:/tmp/ext-plugins
      - $PWD/misc:/tmp/misc
      - $PWD/config:/tmp/config
      - $PWD/jmx-exporter:/tmp/jmx/

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    platform: linux/amd64
    ports:
      - 8090:8080
    depends_on:
      - broker
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: "1.5g"
        reservations:
          cpus: '0.5'
          memory: "1.5g"

  # Uncomment the following lines to enable ksqlDB server and Redpanda Console
  # ksqldb-server:
  #   image: confluentinc/cp-ksqldb-server:7.6.1
  #   hostname: ksqldb-server
  #   container_name: ksqldb-server
  #   depends_on:
  #     - broker
  #     - connect
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     KSQL_CONFIG_DIR: "/etc/ksql"
  #     KSQL_BOOTSTRAP_SERVERS: "broker:29092"
  #     KSQL_HOST_NAME: ksqldb-server
  #     KSQL_LISTENERS: "http://0.0.0.0:8088"
  #     KSQL_CACHE_MAX_BYTES_BUFFERING: 0
  #     KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  #     KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  #     KSQL_KSQL_CONNECT_URL: "http://connect:8083"
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
  #     KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: "2g"
  #       reservations:
  #         cpus: '0.5'
  #         memory: "2g"
  # redpanda-console:
  #   image: docker.redpanda.com/redpandadata/console:latest
  #   # network_mode: "host"
  #   environment:
  #     - KAFKA_BROKERS=broker:29092
  #   ports:
  #     - "8090:8080"


  # kafkacat:
  #   image: edenhill/kafkacat:1.7.0-PRE1
  #   container_name: kafkacat
  #   entrypoint: 
  #     - /bin/sh 
  #     - -c 
  #     - |
  #       apk add jq; 
  #       while [ 1 -eq 1 ];do sleep 60;done

#####################################################
#### Airflow Services ###############################
#####################################################

  # db:
  #   container_name: postgres_weather_data
  #   image: postgres:15.13
  #   environment:
  #     POSTGRES_USER: db_user
  #     POSTGRES_PASSWORD: db_password
  #     POSTGRES_DB: db
  #   ports:
  #     - "5432:5432"
  #   volumes:
  #     - ./postgres/data:/var/lib/postgresql/data
  #     - ./postgres/airflow_init.sql:/docker-entrypoint-initdb.d/airflow_init.sql
  #     # networks:
  #     #   - my_network

  # af:
  #   container_name: airflow_weather_data
  #   image: apache/airflow:3.0.2
  #   environment:
  #     AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@db:5432/airflow_db
  #   ports:
  #     - "9050:8080"
  #   depends_on:
  #     - db
  #   volumes:
  #     - ./airflow/dags:/opt/airflow/dags
  #     - ./producers:/opt/airflow/producers
  #     - /var/run/docker.sock:/var/run/docker.sock

  #   group_add:
  #     - 1001
  #     # networks:
  #     #   - my_network
  #   command: >
  #     bash -c "sleep 10 && airflow db migrate && airflow standalone"

#####################################################
#### Spark Cluster ##################################
#####################################################

  # spark-master:
  #   image: yourorg/spark-custom:3.4.2 
  #   build: .
  #   container_name: spark-master
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #   ports:
  #     - "8082:8060"   # Spark Web UI
  #     - "7077:7077"   # Spark master port
  #     - "4043:4040"   # Spark Driver UI
  #   volumes:
  #     - ./spark/jobs:/opt/bitnami/spark/app
  #     - ./logs:/logs:rw
  #     - ./spark-plugins:/opt/spark-plugins
  #   networks:
  #     - default
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2'
  #         memory: '8g'
  #       reservations:
  #         cpus: '2'
  #         memory: '8g'

  # spark-worker-1:
  #   image: yourorg/spark-custom:3.4.2 
  #   build: .
  #   container_name: spark-worker-1
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=4G
  #     - SPARK_WORKER_CORES=1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8084:8082"  # Spark worker UI
  #   volumes:
  #     - ./spark/jobs:/opt/bitnami/spark/app
  #     - ./spark-plugins:/opt/spark-plugins
  #   networks:
  #     - default
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1'
  #         memory: '2g'
  #       reservations:
  #         cpus: '1'
  #         memory: '2g'

  # spark-worker-2:
  #   image: yourorg/spark-custom:3.4.2 
  #   build: .
  #   container_name: spark-worker-2
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=4G
  #     - SPARK_WORKER_CORES=1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8075:8082"  # Spark worker UI
  #   volumes:
  #     - ./spark/jobs:/opt/bitnami/spark/app
  #     - ./spark-plugins:/opt/spark-plugins
  #   networks:
  #     - default
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1'
  #         memory: '2g'
  #       reservations:
  #         cpus: '1'
  #         memory: '2g'

  # spark-worker-3:
  #   image: yourorg/spark-custom:3.4.2 
  #   build: .
  #   container_name: spark-worker-3
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=4G
  #     - SPARK_WORKER_CORES=1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8086:8082"  # Spark worker UI
  #   volumes:
  #     - ./spark/jobs:/opt/bitnami/spark/app
  #     - ./spark-plugins:/opt/spark-plugins
  #   networks:
  #     - default
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1'
  #         memory: '2g'
  #       reservations:
  #         cpus: '1'
  #         memory: '2g'

  # spark-worker-4:
  #   image: yourorg/spark-custom:3.4.2 
  #   build: .
  #   container_name: spark-worker-4
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=4G
  #     - SPARK_WORKER_CORES=1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8088:8082"  # Spark worker UI
  #   volumes:
  #     - ./spark/jobs:/opt/bitnami/spark/app
  #     - ./spark-plugins:/opt/spark-plugins
  #   networks:
  #     - default
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '1'
  #         memory: '2g'
  #       reservations:
  #         cpus: '1'
  #         memory: '2g'

#####################################################
#### MONITORING AND ALERTING ########################
#####################################################
#   prometheus:
#     image: prom/prometheus:v2.47.2
#     container_name: prometheus
#     ports:
#       - "9090:9090"
#     volumes:
#       - ./prometheus:/etc/prometheus
#     deploy:
#       resources:
#         limits:
#           cpus: '0.5'
#           memory: "512m"
#         reservations:
#           cpus: '0.5'
#           memory: "512m"

#   alertmanager:
#     image: prom/alertmanager:v0.26.0
#     container_name: alertmanager
#     ports:
#       - "19093:9093"

#   grafana:
#     image: grafana/grafana:latest
#     container_name: grafana
#     ports:
#       - "3000:3000"
#     deploy:
#       resources:
#         limits:
#           cpus: '0.5'
#           memory: "512m"
#         reservations:
#           cpus: '0.5'
#           memory: "512m"
#     volumes:
#       - grafana-data:/var/lib/grafana
#       - ./grafana/provisioning:/etc/grafana/provisioning

# volumes:
#   grafana-data: